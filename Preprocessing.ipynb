{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9cab022b-f41e-4998-be64-cb37ac7780df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "#####################\n",
    "# Import of utils.py functions\n",
    "#####################\n",
    "root_dir = os.getcwd()\n",
    "sys.path.append('.')\n",
    "from utils import loadFSL, FSLeyesServer\n",
    "\n",
    "####################\n",
    "# DIPY_HOME should be set prior to import of dipy to make sure all downloads point to the right folder\n",
    "####################\n",
    "\n",
    "# ???\n",
    "# os.environ[\"DIPY_HOME\"] = \"/home/jovyan/Data\"\n",
    "\n",
    "#############################\n",
    "# Loading fsl and freesurfer within Neurodesk\n",
    "# You can find the list of available other modules by clicking on the \"Softwares\" tab on the left\n",
    "#############################\n",
    "import lmod\n",
    "await lmod.purge(force=True)\n",
    "await lmod.load('fsl/6.0.7.4')\n",
    "await lmod.load('freesurfer/7.4.1')\n",
    "await lmod.list()\n",
    "\n",
    "####################\n",
    "# Setup FSL path\n",
    "####################\n",
    "loadFSL()\n",
    "\n",
    "###################\n",
    "# Load all relevant libraries\n",
    "##################\n",
    "import fsl.wrappers\n",
    "from fsl.wrappers import fslmaths, flirt, fast, bet\n",
    "from fsl.wrappers.misc import fslroi\n",
    "import mne_nirs\n",
    "import nilearn\n",
    "from nilearn.datasets import fetch_development_fmri\n",
    "import mne\n",
    "import mne_nirs\n",
    "import dipy\n",
    "from dipy.data import fetch_bundles_2_subjects, read_bundles_2_subjects\n",
    "import xml.etree.ElementTree as ET\n",
    "import os.path as op\n",
    "import nibabel as nib\n",
    "import glob\n",
    "\n",
    "import ants\n",
    "\n",
    "import openneuro\n",
    "from mne.datasets import sample\n",
    "from mne_bids import BIDSPath, read_raw_bids, print_dir_tree, make_report\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2bb92300-b457-4f4a-b451-dd3120e61774",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cleanup previously defined data\n",
    "os.system(\"rm -rf dataset/derivatives\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e418cca-aa8c-4894-b2d0-fbb4a95bdf21",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gtk-Message: 10:51:00.951: Failed to load module \"canberra-gtk-module\"\n"
     ]
    }
   ],
   "source": [
    "%gui wx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f3943d5-94d9-40e4-b0f7-ab0aa6168517",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10:51:06: Debug: Adding duplicate image handler for 'Windows bitmap file'\n",
      "10:51:06: Debug: Adding duplicate animation handler for '1' type\n",
      "10:51:06: Debug: Adding duplicate animation handler for '2' type\n",
      "10:51:06: Debug: Adding duplicate image handler for 'Windows bitmap file'\n",
      "10:51:06: Debug: Adding duplicate animation handler for '1' type\n",
      "10:51:06: Debug: Adding duplicate animation handler for '2' type\n",
      "\n",
      "(ipykernel_launcher.py:15137): Gtk-CRITICAL **: 10:51:06.295: gtk_window_resize: assertion 'height > 0' failed\n"
     ]
    }
   ],
   "source": [
    "fsleyesDisplay = FSLeyesServer()\n",
    "fsleyesDisplay.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3658ada5-0ce1-414c-9dc1-fc2e184ac156",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating derivative root and saving some useful paths\n",
    "subject = \"subject101410\"\n",
    "\n",
    "bids_root = op.join(root_dir, \"dataset\")\n",
    "subject_root = op.join(bids_root, subject)\n",
    "\n",
    "derivatives_root = op.join(bids_root, \"derivatives\")\n",
    "os.makedirs(derivatives_root, exist_ok=True)\n",
    "preproc_root = op.join(derivatives_root, \"preprocessed_data\")\n",
    "os.makedirs(preproc_root, exist_ok=True)\n",
    "subject_preproc_root = op.join(preproc_root, subject)\n",
    "os.makedirs(subject_preproc_root, exist_ok=True)\n",
    "\n",
    "anat_path = op.join(subject_root, \"T1w\", \"T1w.nii.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a0e63fb6-1fdb-46b9-968f-33babc37194d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(ipykernel_launcher.py:15137): Gdk-WARNING **: 10:52:05.108: gdkdrawable-x11.c:952 drawable is not a pixmap or window\n"
     ]
    }
   ],
   "source": [
    "fsleyesDisplay.resetOverlays()\n",
    "fsleyesDisplay.load(anat_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5d1b01e0-9d8c-41b2-8954-b131d494ed21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Usage:    bet <input> <output> [options]\n",
      "\n",
      "Main bet2 options:\n",
      "  -o          generate brain surface outline overlaid onto original image\n",
      "  -m          generate binary brain mask\n",
      "  -s          generate approximate skull image\n",
      "  -n          don't generate segmented brain image output\n",
      "  -f <f>      fractional intensity threshold (0->1); default=0.5; smaller values give larger brain outline estimates\n",
      "  -g <g>      vertical gradient in fractional intensity threshold (-1->1); default=0; positive values give larger brain outline at bottom, smaller at top\n",
      "  -r <r>      head radius (mm not voxels); initial surface sphere is set to half of this\n",
      "  -c <x y z>  centre-of-gravity (voxels not mm) of initial mesh surface.\n",
      "  -t          apply thresholding to segmented brain image and mask\n",
      "  -e          generates brain surface as mesh in .vtk format\n",
      "\n",
      "Variations on default bet2 functionality (mutually exclusive options):\n",
      "  (default)   just run bet2\n",
      "  -R          robust brain centre estimation (iterates BET several times)\n",
      "  -S          eye & optic nerve cleanup (can be useful in SIENA - disables -o option)\n",
      "  -B          bias field & neck cleanup (can be useful in SIENA)\n",
      "  -Z          improve BET if FOV is very small in Z (by temporarily padding end slices)\n",
      "  -F          apply to 4D FMRI data (uses -f 0.3 and dilates brain mask slightly)\n",
      "  -A          run bet2 and then betsurf to get additional skull and scalp surfaces (includes registrations)\n",
      "  -A2 <T2>    as with -A, when also feeding in non-brain-extracted T2 (includes registrations)\n",
      "\n",
      "Miscellaneous options:\n",
      "  -v          verbose (switch on diagnostic messages)\n",
      "  -h          display this help, then exits\n",
      "  -d          debug (don't delete temporary intermediate images)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "256"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To display the commands and how to use the \"bet\" command\n",
    "os.system(\"bet -h\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "61b33f7e-e5c9-419e-9253-84f07d1115a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skull stripping with BET succeeded!\n"
     ]
    }
   ],
   "source": [
    "# Skull stripping with \"bet\"\n",
    "robust: bool = True\n",
    "\n",
    "# Define the path where to save the file\n",
    "os.makedirs(op.join(subject_preproc_root, \"T1w\"), exist_ok=True)\n",
    "betted_brain_path = op.join(subject_preproc_root, \"T1w\", \"T1w_skull.nii.gz\")\n",
    "\n",
    "# Apply \"bet\" and save the file\n",
    "robust_text = \"-R\" if robust else \"\"\n",
    "os.system(f\"bet {anat_path} {betted_brain_path} -m {robust_text}\")\n",
    "\n",
    "# BET also creates a resulting Mask that is useful to display\n",
    "resulting_mask = op.join(subject_preproc_root, \"T1w\", \"T1w_skull_mask.nii.gz\")\n",
    "\n",
    "print(\"Skull stripping with BET succeeded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0095c3f9-93eb-41ca-b751-733bbc17d3b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the Skull Stripped Image\n",
    "fsleyesDisplay.load(resulting_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "651ba121-dfac-4f48-b96b-63ebc06d09e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we have to apply the mask to the image\n",
    "def apply_fsl_math_approach(img_path, mask_path, masked_img_path):\n",
    "    os.system(f'fslmaths {img_path} -mas {mask_path} {masked_img_path}')\n",
    "\n",
    "apply_fsl_math_approach(anat_path, resulting_mask, betted_brain_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8faeb725-fc98-433f-9aed-965eb8f07017",
   "metadata": {},
   "outputs": [],
   "source": [
    "fsleyesDisplay.resetOverlays()\n",
    "fsleyesDisplay.load(betted_brain_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "573d8cdf-823c-4af3-b212-2694fe6bb0be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Part of FSL (ID: \"\")\n",
      "FAST \n",
      "Copyright(c) 2004-2012, University of Oxford\n",
      "\n",
      "Usage: \n",
      "fast [options] file(s)\n",
      "\n",
      "Optional arguments (You may optionally specify one or more of):\n",
      "\t-n,--class\tnumber of tissue-type classes; default=3\n",
      "\t-I,--iter\tnumber of main-loop iterations during bias-field removal; default=4\n",
      "\t-l,--lowpass\tbias field smoothing extent (FWHM) in mm; default=20\n",
      "\t-t,--type\ttype of image 1=T1, 2=T2, 3=PD; default=T1\n",
      "\t-f,--fHard\tinitial segmentation spatial smoothness (during bias field estimation); default=0.02\n",
      "\t-g,--segments\toutputs a separate binary image for each tissue type\n",
      "\t-a <standard2input.mat> initialise using priors; you must supply a FLIRT transform\n",
      "\t-A <prior1> <prior2> <prior3>    alternative prior images\n",
      "\t--nopve\tturn off PVE (partial volume estimation)\n",
      "\t-b\t\toutput estimated bias field\n",
      "\t-B\t\toutput bias-corrected image\n",
      "\t-N,--nobias\tdo not remove bias field\n",
      "\t-S,--channels\tnumber of input images (channels); default 1\n",
      "\t-o,--out\toutput basename\n",
      "\t-P,--Prior\tuse priors throughout; you must also set the -a option\n",
      "\t-W,--init\tnumber of segmentation-initialisation iterations; default=15\n",
      "\t-R,--mixel\tspatial smoothness for mixeltype; default=0.3\n",
      "\t-O,--fixed\tnumber of main-loop iterations after bias-field removal; default=4\n",
      "\t-H,--Hyper\tsegmentation spatial smoothness; default=0.1\n",
      "\t-v,--verbose\tswitch on diagnostic messages\n",
      "\t-h,--help\tdisplay this message\n",
      "\t-s,--manualseg <filename> Filename containing intensities\n",
      "\t-p\t\toutputs individual probability maps\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "256"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.system(\"fast -h\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8186a222-6d55-4545-a494-a3f12fa14991",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tissue segmentation\n",
    "fast_output_path = op.join(subject_preproc_root, \"T1w\", \"T1w_fasted\")\n",
    "fast_target = betted_brain_path \n",
    "\n",
    "# Quick cleanup\n",
    "[os.remove(f) for f in glob.glob(op.join(subject_preproc_root, \"T1w\", '*fast*'))]\n",
    "\n",
    "fast(imgs=[fast_target], out=fast_output_path, n_classes=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3d26b917-f50d-4298-9107-b5b4cdbf0703",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|preprocessed_data/\n",
      "|--- subject101410/\n",
      "|------ T1w/\n",
      "|--------- T1w_fasted_mixeltype.nii.gz\n",
      "|--------- T1w_fasted_pve_0.nii.gz\n",
      "|--------- T1w_fasted_pve_1.nii.gz\n",
      "|--------- T1w_fasted_pve_2.nii.gz\n",
      "|--------- T1w_fasted_pveseg.nii.gz\n",
      "|--------- T1w_fasted_seg.nii.gz\n",
      "|--------- T1w_skull.nii.gz\n",
      "|--------- T1w_skull_mask.nii.gz\n"
     ]
    }
   ],
   "source": [
    "print_dir_tree(preproc_root, max_depth=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "58c23497-fac5-43de-b328-959c71ce671f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fsleyesDisplay.resetOverlays()\n",
    "fsleyesDisplay.load(betted_brain_path)\n",
    "fsleyesDisplay.load(glob.glob(op.join(subject_preproc_root, 'T1w','*pve_0*'))[0])\n",
    "fsleyesDisplay.load(glob.glob(op.join(subject_preproc_root, 'T1w','*pve_1*'))[0])\n",
    "fsleyesDisplay.load(glob.glob(op.join(subject_preproc_root, 'T1w','*pve_2*'))[0])\n",
    "fsleyesDisplay.displayCtx.getOpts(fsleyesDisplay.overlayList[1]).cmap = 'Red'\n",
    "fsleyesDisplay.displayCtx.getOpts(fsleyesDisplay.overlayList[2]).cmap = 'Green'\n",
    "fsleyesDisplay.displayCtx.getOpts(fsleyesDisplay.overlayList[3]).cmap = 'Blue'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a9eba16-8c23-4437-b52f-c45bc95e74aa",
   "metadata": {},
   "source": [
    "## I have checked and made sure everything works up to here, Check what is going on later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243b5edc-edbc-4093-ba77-85075725588f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking what does RL and LR mean\n",
    "\n",
    "func_LR_path = op.join(subject_root, 'fMRI', 'tfMRI_MOTOR_LR','tfMRI_MOTOR_LR.nii')\n",
    "func_RL_path = op.join(subject_root, 'fMRI', 'tfMRI_MOTOR_RL','tfMRI_MOTOR_RL.nii')\n",
    "\n",
    "# fsleyesDisplay.resetOverlays()\n",
    "# fsleyesDisplay.load(func_LR_path)\n",
    "# fsleyesDisplay.load(func_RL_path)\n",
    "# same reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51034ca1-4cb8-42a9-a130-c54a82df2812",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaling variance to one\n",
    "import numpy as np\n",
    "temp = nib.load(func_LR_path)\n",
    "LR_func_data= temp.get_fdata()\n",
    "std_LR=LR_func_data.std(axis=(0,1,2))\n",
    "LR_norm = LR_func_data / std_LR\n",
    "LR_norm_img = nib.Nifti1Image(LR_norm.astype(np.uint8), temp.affine, temp.header)\n",
    "# LR_path = op.join(preproc_root, 'fMRI','tfMRI_MOTOR_LR_norm.nii')\n",
    "func_preproc_path = op.join(preproc_root, 'fMRI')\n",
    "os.mkdirs(func_preproc_path, exists_ok=True)\n",
    "nib.save(LR_norm_img, op.join(func_preproc_path,'tfMRI_MOTOR_LR_norm.nii'))\n",
    "\n",
    "temp = nib.load(func_RL_path)\n",
    "RL_func_data= temp.get_fdata()\n",
    "std_RL=RL_func_data.std(axis=(0,1,2))\n",
    "RL_norm = RL_func_data / std_RL\n",
    "RL_norm_img = nib.Nifti1Image(RL_norm.astype(np.uint8), temp.affine, temp.header)\n",
    "# RL_path = op.join(preproc_root, 'fMRI','tfMRI_MOTOR_RL_norm.nii')\n",
    "nib.save(RL_norm_img, op.join(func_preproc_path,'tfMRI_MOTOR_RL_norm.nii'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0f961614-8eec-4552-b204-521bb7339dd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.000000021161999\n"
     ]
    }
   ],
   "source": [
    "# concatenating runs\n",
    "print(LR_norm.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c5588813-345c-44fa-abfc-ee2889d6ba1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sh: 1: merge: not found\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "32512"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subprocess.run(['fslmerge', '-t', merged_phase_imgs, \n",
    "                    op.join(fmap_path, 'sub-001_acq-task_dir-AP_epi.nii.gz'), \n",
    "                    op.join(fmap_path, 'sub-001_acq-task_dir-PA_epi.nii.gz')])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
